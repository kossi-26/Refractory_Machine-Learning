{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pie chart for Target distribution (Overview of outcomes)-Abigaba\n",
        "plt.figure(figsize=(6, 6))\n",
        "df['Target'].value_counts().plot.pie(startangle=90,  autopct='%1.1f%%', colors=['#1f77b4', '#ff7f0e'], textprops={'fontsize': 14})\n",
        "plt.title('Student Outcomes at a Glance', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('')\n",
        "plt.savefig('target_pie.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation (Univariate) - This pie chart shows the distribution of student outcomes, with the majority being graduates, indicating a class imbalance where dropouts are less frequent but critical to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Age bar plot -Abigaba\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['Age at enrollment'], bins=6, color='skyblue', kde=False, edgecolor='black')\n",
        "plt.title('Age Distribution', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Age', fontsize=14)\n",
        "plt.ylabel('Number of Students', fontsize=14)\n",
        "plt.savefig('age_bar.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation (Univariate) - The age distribution is right-skewed, with most students in their 20s, suggesting that many are recent high school graduates. Older students are less common, which may reflect different enrollment or dropout patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Admission grade bar plot - Abigaba\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['Admission grade'], bins=15, kde=False, color='lightgreen', edgecolor='black')\n",
        "plt.title('Admission Grades', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Grade', fontsize=14)\n",
        "plt.ylabel('Number of Students', fontsize=14)\n",
        "plt.savefig('admission_bar.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation (Univariate) - Admission grades follow a normal distribution centered around 120-140, with fewer low scores, implying the dataset captures relatively high-performing students overall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar plot for mean Admission grade by Target\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x='Target', y='Admission grade', data=df, palette='Set2', errorbar=None)  # keep default CI or set errorbar='sd' for std\n",
        "plt.title('Admission Grades vs. Graduation', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Graduation Outcome', fontsize=14)\n",
        "plt.ylabel('Average Admission Grade', fontsize=14)\n",
        "plt.savefig('admission_by_target_bar.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation (Bivariate) - Both dropouts and graduates have relatively high admission grades, with only a small difference, suggesting that while academic performance matters, other non-academic factors also play a significant role in determining graduation outcomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stacked bar for School Distance by Location Type\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data=df, x='School_Distance_km', hue='Location_Type', multiple='stack', palette=['#1f77b4', '#ff7f0e'], bins=10, edgecolor='black', alpha=0.8  )\n",
        "plt.title('School Travel Distance by Location', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Distance to School (km)', fontsize=14)\n",
        "plt.ylabel('Number of Students', fontsize=14)\n",
        "plt.savefig('school_distance_stacked.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation (Multivariate) - Rural students generally travel farther to school compared to urban students, which may increase the risk of dropouts due to accessibility challenges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar plot for mean Internet Access by Target\n",
        "df_filtered = df[df['Target'].isin(['Dropout', 'Graduate'])].copy()\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x='Target', y='Internet_Access', data=df_filtered, palette='Set1', errorbar=None)\n",
        "plt.title('Internet Access by Graduation Outcome', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Graduation Outcome', fontsize=14)\n",
        "plt.ylabel('Average Internet Access Score', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig('internet_by_target_bar.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation (Bivariate) - Graduation outcomes show little variation in internet access scores, indicating that factors beyond connectivity are likely more influential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Horizontal bar plot of top correlations with Target\n",
        "num_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "corr_with_target = num_df.corr()['y'].abs().drop('y').sort_values(ascending=False)\n",
        "top_corr = corr_with_target.head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_corr.sort_values().plot(kind='barh', color=sns.color_palette('bright', len(top_corr)))\n",
        "plt.title('Top 10 Factors Influencing Graduation', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Correlation Strength', fontsize=14)\n",
        "plt.ylabel('Features', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig('top_correlations_barh.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation (Bivariate) - These are the top 10 features most strongly associated with graduation, showing that academic factors dominate, while non-academic influences also contribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72kT2NZ2fRrf"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing - Rwotolara Innocent\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "print('Shape after removing duplicates:', df.shape)\n",
        "\n",
        "# Handle outliers in key numerical features\n",
        "for col in ['Age at enrollment', 'Admission grade', 'School_Distance_km']:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "    print(f'Shape after removing outliers in {col}: {df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGHBsijpf8p8"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing - Rwotolara Innocent\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "print('Shape after removing duplicates:', df.shape)\n",
        "\n",
        "# Handle outliers in key numerical features\n",
        "for col in ['Age at enrollment', 'Admission grade', 'School_Distance_km']:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "    print(f'Shape after removing outliers in {col}: {df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cRquoIIgAub"
      },
      "outputs": [],
      "source": [
        "# PCA Implementation - Rwotolara Innocent\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "print('Shape after PCA:', X_pca.shape)\n",
        "print('Variance retained:', pca.explained_variance_ratio_.sum()).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCe2-TlEgBeD"
      },
      "outputs": [],
      "source": [
        "# Plot PCA elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('PCA Elbow Curve')\n",
        "plt.grid(True)\n",
        "plt.savefig('pca_elbow_curve.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLU_GCl6gKGE"
      },
      "source": [
        "**Interpretation (PCA)** - The first few components capture most of the important structure in the data, with diminishing returns as more components are added. The “elbow” around 10-12 components suggests an optimal balance, providing most of the information without unnecessary dimensions. By 15-20 components, over 80% of the variance is already explained, so including more offers little additional benefit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7Lqh1zXgMnn"
      },
      "outputs": [],
      "source": [
        "# PCA Implementation - Rwotolara Innocent\n",
        "# Feature Importance Ranking After PCA\n",
        "feature_names = X_encoded.columns.tolist()\n",
        "\n",
        "feature_importance = np.sum(np.abs(pca.components_), axis=0)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Importance\": feature_importance\n",
        "}).sort_values(\"Importance\", ascending=True)\n",
        "\n",
        "# Plot features ranked by importance\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color=\"skyblue\")\n",
        "plt.xlabel(\"Feature Importance\", fontsize=12)\n",
        "plt.title(\"Original Features Ranked by Importance After PCA\", fontsize=14, fontweight=\"bold\")\n",
        "plt.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
        "plt.savefig(\"pca_feature_importance.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBelPXIXgRVS"
      },
      "source": [
        "**Interpretation (PCA Feature Importance)** - This plot shows the original features ranked by their contribution to the principal components retained in PCA. Features with higher importance scores have a stronger influence on the transformed PCA space used for modeling. Both academic and non-academic factors contribute, highlighting which variables drive the variance in the dataset and are most influential in predicting student outcomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4gbaQh7gSK7"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing - Rwotolara Innocent\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
